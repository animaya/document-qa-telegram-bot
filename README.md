# Document QA Telegram Bot

A Telegram bot that allows users to upload PDF documents and ask questions about their content. The bot uses Anthropic's Claude Haiku model and implements advanced Retrieval-Augmented Generation (RAG) techniques based on Anthropic's Contextual Retrieval approach.

## Features

- Upload multiple PDF documents through Telegram
- Process and index documents for efficient retrieval
- Ask questions about document content
- Get accurate responses using Claude Haiku
- Advanced RAG implementation:
  - Contextual Embeddings
  - Contextual BM25
  - Hybrid retrieval
  - Reranking capabilities
- Independent sessions for each user
- Optimized for cost and speed with the Haiku model

## Architecture

This implementation follows Anthropic's recommended patterns for agentic systems:

1. **Workflow: Prompt Chaining** - For document processing (extract → chunk → contextualize → embed)
2. **Workflow: Orchestrator-Workers** - For the overall system architecture
3. **Building Block: Augmented LLM** - For the QA component with advanced RAG

## Getting Started

### Prerequisites

- Python 3.9 or higher
- Docker and Docker Compose (optional, for containerized deployment)
- API keys:
  - Telegram Bot Token (required)
  - Anthropic API Key (required)
  - One of the following embedding providers:
    - Google Gemini API Key
    - Voyage AI API Key
    - OpenAI API Key
  - Cohere API Key (recommended for reranking)

### Installation

#### Local Installation

1. Clone this repository:
   ```
   git clone https://github.com/yourusername/document-qa-telegram-bot.git
   cd document-qa-telegram-bot
   ```

2. Create a virtual environment and install dependencies:
   ```
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. Create a `.env` file based on the template:
   ```
   cp .env.template .env
   ```

4. Edit the `.env` file and add your API keys.

5. Run the bot:
   ```
   python main.py
   ```

#### Docker Installation

1. Clone this repository:
   ```
   git clone https://github.com/yourusername/document-qa-telegram-bot.git
   cd document-qa-telegram-bot
   ```

2. Create a `.env` file based on the template:
   ```
   cp .env.template .env
   ```

3. Edit the `.env` file and add your API keys.

4. Build and run the Docker container:
   ```
   docker-compose up -d
   ```

### Usage

1. Start a conversation with your bot on Telegram
2. Send `/start` to initialize the bot
3. Upload one or more PDF documents
4. Wait for the processing to complete
5. Ask questions about the content of your documents

## Configuration

You can configure the bot using environment variables:

- `TELEGRAM_TOKEN`: Your Telegram bot token (required)
- `ANTHROPIC_API_KEY`: Your Anthropic API key (required)
- `GEMINI_API_KEY`: Your Google Gemini API key (optional)
- `VOYAGE_API_KEY`: Your Voyage API key (optional)
- `OPENAI_API_KEY`: Your OpenAI API key (optional)
- `COHERE_API_KEY`: Your Cohere API key (optional, for reranking)
- `DATA_DIR`: Directory to store data (default: "data")
- `EMBEDDING_PROVIDER`: Provider for embeddings (GEMINI, VOYAGE, OPENAI) (default: GEMINI)
- `ANTHROPIC_MODEL`: Anthropic model to use (default: claude-3-haiku-20240307)
- `MAX_CHUNK_SIZE`: Maximum size of chunks in tokens (default: 500)
- `CHUNK_OVERLAP`: Overlap between chunks in tokens (default: 100)
- `NUM_CHUNKS_RETRIEVE`: Number of chunks to retrieve (default: 20)
- `NUM_RERANK`: Number of chunks to consider for reranking (default: 150)
- `USE_RERANKING`: Whether to use reranking (1 or 0) (default: 1)

## Contextual Retrieval

This implementation uses Anthropic's Contextual Retrieval approach to improve retrieval accuracy:

1. **Contextual Embeddings**: Each document chunk is contextualized with a brief description of its position and relevance within the overall document, generated by Claude.
2. **Contextual BM25**: The BM25 index is created using the contextualized chunks, improving lexical search.
3. **Hybrid Retrieval**: Both vector similarity and BM25 are used for retrieval, combining semantic and lexical search.
4. **Reranking**: Results are reranked using Cohere's reranking API to prioritize the most relevant chunks.

This approach can significantly reduce retrieval failures compared to traditional RAG systems.

## Project Structure

- `main.py`: Main application entry point
- `telegram_bot.py`: Telegram bot interface
- `document_qa_telegram_bot.py`: Core classes and data models
- `document_processor.py`: Document processing components
- `contextual_rag.py`: Contextual RAG implementation
- `Dockerfile` and `docker-compose.yml`: Docker configuration
- `requirements.txt`: Python dependencies

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgements

- Anthropic for their research on Contextual Retrieval and agent patterns
- The python-telegram-bot team for their excellent Telegram bot framework
- The FAISS team for their efficient vector similarity search implementation